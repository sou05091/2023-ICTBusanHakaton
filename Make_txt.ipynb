{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "# 1. yolov5 설치 (git clone https://github.com/ultralytics/yolov5.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6965\n",
      "YOLOv5용 txt 파일을 생성하였습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "def convert_to_yolo_format(data_list, output_folder):\n",
    "    for image_data in data_list:\n",
    "        image_filename = image_data['file_name']\n",
    "        bbox_data = image_data['bbox_data']\n",
    "\n",
    "        image_path = os.path.join('./dataset/img', image_filename)\n",
    "\n",
    "        txt_filename = os.path.splitext(image_filename)[0] + \".txt\"\n",
    "        txt_filepath = os.path.join(output_folder, txt_filename)\n",
    "\n",
    "        count = 0\n",
    "        with open(txt_filepath, 'w') as txtfile:\n",
    "            for bbox_info in bbox_data:\n",
    "                x_min, y_min, width, height = bbox_info['bbox']\n",
    "                x_max = x_min + width\n",
    "                y_max = y_min + height\n",
    "                class_ids = [0,1,2,3]\n",
    "\n",
    "                # Convert coordinates to YOLO format (normalized)\n",
    "                img_width, img_height = 3000, 4000  # Replace with actual image dimensions\n",
    "                x_center = (x_min + x_max) / (2.0 * img_width)\n",
    "                y_center = (y_min + y_max) / (2.0 * img_height)\n",
    "                w = width / img_width\n",
    "                h = height / img_height\n",
    "                txtfile.write(f\"{class_ids[count]} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "                count += 1\n",
    "\n",
    "def main():\n",
    "    # 폴더 경로 설정\n",
    "    folder_path = './dataset/lab'\n",
    "\n",
    "    # 새로운 파일 경로와 이름\n",
    "    new_file_path = './dataset/etc'\n",
    "\n",
    "    # 모든 데이터를 담을 리스트\n",
    "    all_data = []\n",
    "\n",
    "    # 폴더 내의 모든 파일 목록 가져오기\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    # JSON 파일 목록 필터링\n",
    "\n",
    "    # 파일 개수 확인\n",
    "    file_count = len(file_list)\n",
    "    print(file_count)\n",
    "\n",
    "    # JSON 파일들을 순회하면서 파일 이름과 bbox 데이터 추출\n",
    "    for json_file in file_list:\n",
    "        json_path = os.path.join(folder_path, json_file)\n",
    "\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            images = data.get('images', [])\n",
    "            annotations = data.get('annotations', [])\n",
    "\n",
    "            # 파일 이름과 bbox 데이터 저장\n",
    "            for image in images:\n",
    "                file_name = image.get('file_name', None)\n",
    "                image_id = image.get('id', None)\n",
    "\n",
    "                # 해당 이미지의 머리, 몸통, 꼬리 bbox 추출\n",
    "                bbox_data = []\n",
    "                for annotation in annotations:\n",
    "                    if annotation.get('image_id', None) == image_id:\n",
    "                        category_id = annotation.get('category_id_region', None)\n",
    "                        bbox = annotation.get('bbox', None)\n",
    "                        bbox_data.append({'category_id': category_id, 'bbox': bbox})\n",
    "\n",
    "                data_entry = {\n",
    "                    'file_name': file_name,\n",
    "                    'bbox_data': bbox_data\n",
    "                }\n",
    "                all_data.append(data_entry)\n",
    "\n",
    "    # 새로운 폴더가 없는 경우 생성\n",
    "    os.makedirs(os.path.dirname(new_file_path), exist_ok=True)\n",
    "\n",
    "    # 데이터를 랜덤하게 섞어서 훈련 데이터와 검증 데이터로 분할\n",
    "    random.shuffle(all_data)\n",
    "    train_data = all_data[:int(0.8 * len(all_data))]\n",
    "    val_data = all_data[int(0.8 * len(all_data)):]\n",
    "\n",
    "    # 훈련 데이터와 검증 데이터를 각각 YOLO txt 파일로 저장\n",
    "    train_txt_path = os.path.join(new_file_path, 'train')\n",
    "    val_txt_path = os.path.join(new_file_path, 'val')\n",
    "\n",
    "    os.makedirs(train_txt_path, exist_ok=True)\n",
    "    os.makedirs(val_txt_path, exist_ok=True)\n",
    "\n",
    "    convert_to_yolo_format(train_data, train_txt_path)\n",
    "    convert_to_yolo_format(val_data, val_txt_path)\n",
    "\n",
    "    print('YOLOv5용 txt 파일을 생성하였습니다.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.txt and val.txt files created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "def load_json_data(folder_path):\n",
    "    all_data = []\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    for json_file in file_list:\n",
    "        json_path = os.path.join(folder_path, json_file)\n",
    "\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            images = data.get('images', [])\n",
    "            annotations = data.get('annotations', [])\n",
    "\n",
    "            for image in images:\n",
    "                file_name = image.get('file_name', None)\n",
    "                image_id = image.get('id', None)\n",
    "\n",
    "                bbox_data = []\n",
    "                for annotation in annotations:\n",
    "                    if annotation.get('image_id', None) == image_id:\n",
    "                        category_id = annotation.get('category_id_region', None)\n",
    "                        bbox = annotation.get('bbox', None)\n",
    "                        bbox_data.append({'category_id': category_id, 'bbox': bbox})\n",
    "\n",
    "                data_entry = {\n",
    "                    'file_name': file_name,\n",
    "                    'bbox_data': bbox_data\n",
    "                }\n",
    "                all_data.append(data_entry)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def split_data(all_data):\n",
    "    random.shuffle(all_data)\n",
    "    train_data = all_data[:int(0.8 * len(all_data))]\n",
    "    val_data = all_data[int(0.8 * len(all_data)):]\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "def create_txt_file(data, txt_file_path):\n",
    "    img_path = '../dataset/img/'\n",
    "    with open(txt_file_path, 'w') as txt_file:\n",
    "        for item in data:\n",
    "            txt_file.write(img_path + item['file_name'] + '\\n')\n",
    "            \n",
    "            count = 0\n",
    "            # 추가: bbox 정보를 가져와서 작성\n",
    "            for bbox_info in item['bbox_data']:\n",
    "                # class_id = bbox_info['category_id']\n",
    "                class_ids = [0,1,2,3]\n",
    "                x_min, y_min, width, height = bbox_info['bbox']\n",
    "                \n",
    "                x_max = x_min + width\n",
    "                y_max = y_min + height\n",
    "                \n",
    "                # Convert bbox coordinates to YOLO format (normalized)\n",
    "                img_width, img_height = 3000, 4000  # Replace with actual image dimensions\n",
    "                x_center = (x_min + x_max) / (2.0 * img_width)\n",
    "                y_center = (y_min + y_max) / (2.0 * img_height)\n",
    "                w = width / img_width\n",
    "                h = height / img_height\n",
    "\n",
    "                # Write bbox info to txt file\n",
    "                txt_file.write(f\" {x_center:.6f},{y_center:.6f},{w:.6f},{h:.6f},{class_ids[count]}\")\n",
    "                count += 1\n",
    "\n",
    "            txt_file.write('\\n')\n",
    "\n",
    "def main():\n",
    "    folder_path = './dataset/lab'\n",
    "    new_file_path = './dataset/etc'\n",
    "\n",
    "    all_data = load_json_data(folder_path)\n",
    "    train_data, val_data = split_data(all_data)\n",
    "\n",
    "    os.makedirs(new_file_path, exist_ok=True)\n",
    "\n",
    "    train_txt_path = os.path.join(new_file_path, 'train.txt')\n",
    "    val_txt_path = os.path.join(new_file_path, 'val.txt')\n",
    "\n",
    "    create_txt_file(train_data, train_txt_path)\n",
    "    create_txt_file(val_data, val_txt_path)\n",
    "\n",
    "    print('train.txt and val.txt files created.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to 'yolov8s.pt'...\n",
      "100%|██████████| 21.5M/21.5M [00:42<00:00, 528kB/s] \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python val.py --img 640 --batch 16 --data data.yaml --weights runs/train/my_custom_model/weights/best.pt --task test\n",
    "# python train.py --batch 32 --epochs 10 --data data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt\n",
    "# python train.py --batch 32 --epochs 5 --data data.yaml --cfg models/yolov5s.yaml --weights yolov8s.pt\n",
    "\n",
    "# python train.py --img 640 --batch 16 --epochs 1 --data data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --device 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2730868882631989703\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "local_devices = device_lib.list_local_devices()\n",
    "\n",
    "# 모든 장치 정보 출력\n",
    "print(local_devices)\n",
    "\n",
    "# GPU 정보만 출력\n",
    "# gpu_devices = [x for x in local_devices if 'GPU' in x.device_type]\n",
    "# print(gpu_devices)\n",
    "\n",
    "# CPU 정보만 출력\n",
    "# cpu_devices = [x for x in local_devices if 'CPU' in x.device_type]\n",
    "# print(cpu_devices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 18242263868752044040\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
